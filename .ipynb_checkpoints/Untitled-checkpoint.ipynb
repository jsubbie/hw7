{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies \n",
    "\n",
    "import os \n",
    "import pandas as pd \n",
    "import tweepy \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import requests as req\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API keys & Tweepy Authentication \n",
    "\n",
    "# Twitter API Keys\n",
    "consumer_key = \"uqWxn83alfwZNumLlvhO2Wv3c\"\n",
    "consumer_secret = \"bttQrkHniBnVK1Ejiz2lr2hTm3kgnvB1lU9anXEaJoPxMCdtdH\"\n",
    "access_token = \"145916665-EWEaAZsNq0VAOfGqKI5tPyDLcOD1SzzOrwStadiJ\"\n",
    "access_token_secret = \"YAOzvQQziom4i30VnvlteJjDYMxpXdCRDalrRa5HciXhM\"\n",
    "\n",
    "# Tweepy \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- begin request ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute '_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c94b56062d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#public_tweets = api.user_timeline(user)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute '_json'"
     ]
    }
   ],
   "source": [
    "# Target User Account\n",
    "target_user = [\"@BBC\", \"@CBS\", \"@CNN\", \"@FoxNews\", \"@nytimes\"]\n",
    "\n",
    "# Counter\n",
    "counter = 1\n",
    "\n",
    "print(\"--- begin request ---\")\n",
    "\n",
    "#Loop through each user\n",
    "for user in target_user:\n",
    "\n",
    "    # Variables for holding sentiments\n",
    "    compound = []\n",
    "    pos = []\n",
    "    neg = []\n",
    "    neu = []\n",
    "\n",
    "    # Loop through 5 pages of tweets (total 100 tweets)\n",
    "    for page in tweepy.Cursor(api.user_timeline, id=user).pages(5):\n",
    "\n",
    "        # get 100 tweets and convert to json \n",
    "        page = [0]\n",
    "        tweet = json.dumps(page._json, indent=3)\n",
    "        tweet = json.loads(tweet)\n",
    "        text = tweet['text']\n",
    "\n",
    "        # Run Vader Analysis on each tweet\n",
    "        compound = analyzer.polarity_scores(text)[\"compound\"]\n",
    "        pos = analyzer.polarity_scores(text)[\"pos\"]\n",
    "        neu = analyzer.polarity_scores(text)[\"neu\"]\n",
    "        neg = analyzer.polarity_scores(text)[\"neg\"]\n",
    "\n",
    "        # Add each value to the appropriate array\n",
    "        compound_list.append(compound)\n",
    "        positive_list.append(pos)\n",
    "        negative_list.append(neg)\n",
    "        neutral_list.append(neu)\n",
    "\n",
    "    # Print the Averages for each user\n",
    "    \n",
    "        print(\"\")\n",
    "        print(\"User: %s\" % user)\n",
    "\n",
    "        print(\"--- request complete --- \")\n",
    "    \n",
    "        print(\"--- next request in 30 seconds ---\")\n",
    "        # Timer\n",
    "        time.sleep(30)\n",
    "\n",
    "        # Add to counter \n",
    "        counter = counter + 1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
